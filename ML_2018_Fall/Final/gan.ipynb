{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')  # allows code to run without a system DISPLAY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, width=32, height=32, channels=1):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.channels = channels\n",
    "\n",
    "        self.shape = (self.width, self.height, self.channels)\n",
    "\n",
    "        self.optimizer = Adam(lr=0.0002, beta_1=0.5, decay=8e-8)\n",
    "\n",
    "        self.G = self.__generator()\n",
    "        self.G.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "\n",
    "        self.D = self.__discriminator()\n",
    "        self.D.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=self.optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        self.stacked_generator_discriminator = self.__stacked_generator_discriminator(\n",
    "        )\n",
    "        self.stacked_generator_discriminator.compile(\n",
    "            loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "\n",
    "    def __generator(self):\n",
    "        \"\"\" Declare generator \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_shape=(100, )))\n",
    "        model.add(LeakyReLU(\n",
    "            alpha=0.2))  # Using leaky relu as internal activation function\n",
    "        model.add(BatchNormalization(\n",
    "            momentum=0.8))  # Optimize with BatchNormalization\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(\n",
    "            Dense(self.width * self.height * self.channels, activation='tanh')\n",
    "        )  # Using tanh as the final layer's activation function\n",
    "        model.add(Reshape((self.width, self.height, self.channels)))\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def __discriminator(self):\n",
    "        \"\"\" Declare discriminator \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=self.shape))\n",
    "        model.add(\n",
    "            Dense((self.width * self.height * self.channels),\n",
    "                  input_shape=self.shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(int((self.width * self.height * self.channels) / 2)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def __stacked_generator_discriminator(self):\n",
    "        self.D.trainable = False\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(self.G)\n",
    "        model.add(self.D)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, epochs=10000, batch=32, save_interval=100):\n",
    "        for cnt in range(epochs + 1):\n",
    "            ## train discriminator\n",
    "            random_index = np.random.randint(0, len(X_train) - batch / 2)\n",
    "            legit_images = X_train[random_index:random_index +\n",
    "                                   int(batch / 2)].reshape(\n",
    "                                       int(batch / 2), self.width, self.height,\n",
    "                                       self.channels)\n",
    "\n",
    "            gen_noise = np.random.normal(0, 1, (int(batch / 2), 100))\n",
    "            syntetic_images = self.G.predict(gen_noise)\n",
    "\n",
    "            x_combined_batch = np.concatenate((legit_images, syntetic_images))\n",
    "            y_combined_batch = np.concatenate((np.ones((int(batch / 2), 1)),\n",
    "                                               np.zeros((int(batch / 2), 1))))\n",
    "\n",
    "            d_loss = self.D.train_on_batch(x_combined_batch, y_combined_batch)\n",
    "\n",
    "            # train generator\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch, 100))  # add Gaussian noises\n",
    "            y_mislabled = np.ones((batch, 1))\n",
    "\n",
    "            g_loss = self.stacked_generator_discriminator.train_on_batch(\n",
    "                noise, y_mislabled)\n",
    "\n",
    "            print(\n",
    "                'epoch: %d, [Discriminator :: d_loss: %f], [ Generator :: loss: %f]'\n",
    "                % (cnt, d_loss[0], g_loss))\n",
    "\n",
    "            if cnt % save_interval == 0:\n",
    "                self.plot_images(save2file=True, step=cnt)\n",
    "\n",
    "    def plot_images(self, save2file=False, samples=16, step=0):\n",
    "        ''' Plot and generated images '''\n",
    "        filename = \"./images/bike_%d.png\" % step\n",
    "        noise = np.random.normal(0, 1, (samples, 100))\n",
    "\n",
    "        images = self.G.predict(noise)\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.height, self.width])\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save2file:\n",
    "            plt.savefig(filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_img = \"./images\"\n",
    "if not os.path.exists(saved_img):\n",
    "    os.makedirs(saved_img)\n",
    "files = [\"./data/train/bike/\" + f for f in os.listdir(\"./data/train/bike\")]\n",
    "X = []\n",
    "y = []\n",
    "for img in files:\n",
    "    data = cv2.imread(img, cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "    data = cv2.resize(data, (32, 32))\n",
    "    label = 0\n",
    "    X.append(data)\n",
    "    y.append(label)\n",
    "X_train, _, _, _ = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 32, 32, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,739,520\n",
      "Trainable params: 1,735,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,574,913\n",
      "Trainable params: 1,574,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\CS\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py:479: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, [Discriminator :: d_loss: 0.511724], [ Generator :: loss: 0.590783]\n",
      "epoch: 1, [Discriminator :: d_loss: 0.380976], [ Generator :: loss: 0.700087]\n",
      "epoch: 2, [Discriminator :: d_loss: 0.350381], [ Generator :: loss: 0.803713]\n",
      "epoch: 3, [Discriminator :: d_loss: 0.289390], [ Generator :: loss: 1.079037]\n",
      "epoch: 4, [Discriminator :: d_loss: 0.277482], [ Generator :: loss: 1.404783]\n",
      "epoch: 5, [Discriminator :: d_loss: 0.215204], [ Generator :: loss: 1.925699]\n",
      "epoch: 6, [Discriminator :: d_loss: 0.147955], [ Generator :: loss: 2.332766]\n",
      "epoch: 7, [Discriminator :: d_loss: 0.114482], [ Generator :: loss: 2.833924]\n",
      "epoch: 8, [Discriminator :: d_loss: 0.056039], [ Generator :: loss: 3.129716]\n",
      "epoch: 9, [Discriminator :: d_loss: 0.051504], [ Generator :: loss: 3.277596]\n",
      "epoch: 10, [Discriminator :: d_loss: 0.032148], [ Generator :: loss: 3.330954]\n",
      "epoch: 11, [Discriminator :: d_loss: 0.037863], [ Generator :: loss: 3.658172]\n",
      "epoch: 12, [Discriminator :: d_loss: 0.028895], [ Generator :: loss: 3.698120]\n",
      "epoch: 13, [Discriminator :: d_loss: 0.042438], [ Generator :: loss: 3.820007]\n",
      "epoch: 14, [Discriminator :: d_loss: 0.027280], [ Generator :: loss: 3.927243]\n",
      "epoch: 15, [Discriminator :: d_loss: 0.030431], [ Generator :: loss: 3.916532]\n",
      "epoch: 16, [Discriminator :: d_loss: 0.021183], [ Generator :: loss: 4.038332]\n",
      "epoch: 17, [Discriminator :: d_loss: 0.021523], [ Generator :: loss: 4.146613]\n",
      "epoch: 18, [Discriminator :: d_loss: 0.009745], [ Generator :: loss: 4.156775]\n",
      "epoch: 19, [Discriminator :: d_loss: 0.032004], [ Generator :: loss: 4.324801]\n",
      "epoch: 20, [Discriminator :: d_loss: 0.021729], [ Generator :: loss: 4.353875]\n",
      "epoch: 21, [Discriminator :: d_loss: 0.019268], [ Generator :: loss: 4.401863]\n",
      "epoch: 22, [Discriminator :: d_loss: 0.014985], [ Generator :: loss: 4.465880]\n",
      "epoch: 23, [Discriminator :: d_loss: 0.018239], [ Generator :: loss: 4.585924]\n",
      "epoch: 24, [Discriminator :: d_loss: 0.010140], [ Generator :: loss: 4.699305]\n",
      "epoch: 25, [Discriminator :: d_loss: 0.017488], [ Generator :: loss: 4.763142]\n",
      "epoch: 26, [Discriminator :: d_loss: 0.017524], [ Generator :: loss: 4.806242]\n",
      "epoch: 27, [Discriminator :: d_loss: 0.007451], [ Generator :: loss: 4.917356]\n",
      "epoch: 28, [Discriminator :: d_loss: 0.018907], [ Generator :: loss: 4.959954]\n",
      "epoch: 29, [Discriminator :: d_loss: 0.012018], [ Generator :: loss: 5.108127]\n",
      "epoch: 30, [Discriminator :: d_loss: 0.011763], [ Generator :: loss: 5.192421]\n",
      "epoch: 31, [Discriminator :: d_loss: 0.014147], [ Generator :: loss: 5.107278]\n",
      "epoch: 32, [Discriminator :: d_loss: 0.007783], [ Generator :: loss: 5.149151]\n",
      "epoch: 33, [Discriminator :: d_loss: 0.016226], [ Generator :: loss: 5.235178]\n",
      "epoch: 34, [Discriminator :: d_loss: 0.005285], [ Generator :: loss: 5.171557]\n",
      "epoch: 35, [Discriminator :: d_loss: 0.017130], [ Generator :: loss: 5.094893]\n",
      "epoch: 36, [Discriminator :: d_loss: 0.002658], [ Generator :: loss: 5.159437]\n",
      "epoch: 37, [Discriminator :: d_loss: 0.010365], [ Generator :: loss: 5.189654]\n",
      "epoch: 38, [Discriminator :: d_loss: 0.009833], [ Generator :: loss: 5.245766]\n",
      "epoch: 39, [Discriminator :: d_loss: 0.023850], [ Generator :: loss: 5.140273]\n",
      "epoch: 40, [Discriminator :: d_loss: 0.006237], [ Generator :: loss: 5.147877]\n",
      "epoch: 41, [Discriminator :: d_loss: 0.004246], [ Generator :: loss: 5.197093]\n",
      "epoch: 42, [Discriminator :: d_loss: 0.014274], [ Generator :: loss: 5.281852]\n",
      "epoch: 43, [Discriminator :: d_loss: 0.003639], [ Generator :: loss: 5.445163]\n",
      "epoch: 44, [Discriminator :: d_loss: 0.005691], [ Generator :: loss: 5.627047]\n",
      "epoch: 45, [Discriminator :: d_loss: 0.010991], [ Generator :: loss: 5.686154]\n",
      "epoch: 46, [Discriminator :: d_loss: 0.007662], [ Generator :: loss: 5.473921]\n",
      "epoch: 47, [Discriminator :: d_loss: 0.009375], [ Generator :: loss: 5.631105]\n",
      "epoch: 48, [Discriminator :: d_loss: 0.002233], [ Generator :: loss: 5.575637]\n",
      "epoch: 49, [Discriminator :: d_loss: 0.009973], [ Generator :: loss: 5.496011]\n",
      "epoch: 50, [Discriminator :: d_loss: 0.019069], [ Generator :: loss: 5.588239]\n",
      "epoch: 51, [Discriminator :: d_loss: 0.010435], [ Generator :: loss: 5.718218]\n",
      "epoch: 52, [Discriminator :: d_loss: 0.008653], [ Generator :: loss: 5.838237]\n",
      "epoch: 53, [Discriminator :: d_loss: 0.005356], [ Generator :: loss: 5.772437]\n",
      "epoch: 54, [Discriminator :: d_loss: 0.003517], [ Generator :: loss: 5.904150]\n",
      "epoch: 55, [Discriminator :: d_loss: 0.005158], [ Generator :: loss: 6.035595]\n",
      "epoch: 56, [Discriminator :: d_loss: 0.017514], [ Generator :: loss: 5.951022]\n",
      "epoch: 57, [Discriminator :: d_loss: 0.010697], [ Generator :: loss: 5.981953]\n",
      "epoch: 58, [Discriminator :: d_loss: 0.008977], [ Generator :: loss: 5.698089]\n",
      "epoch: 59, [Discriminator :: d_loss: 0.011884], [ Generator :: loss: 6.050498]\n",
      "epoch: 60, [Discriminator :: d_loss: 0.008259], [ Generator :: loss: 6.000860]\n",
      "epoch: 61, [Discriminator :: d_loss: 0.006153], [ Generator :: loss: 5.921651]\n",
      "epoch: 62, [Discriminator :: d_loss: 0.006558], [ Generator :: loss: 5.792808]\n",
      "epoch: 63, [Discriminator :: d_loss: 0.013854], [ Generator :: loss: 5.965405]\n",
      "epoch: 64, [Discriminator :: d_loss: 0.003576], [ Generator :: loss: 6.096145]\n",
      "epoch: 65, [Discriminator :: d_loss: 0.016590], [ Generator :: loss: 6.020662]\n",
      "epoch: 66, [Discriminator :: d_loss: 0.003698], [ Generator :: loss: 6.046736]\n",
      "epoch: 67, [Discriminator :: d_loss: 0.005798], [ Generator :: loss: 5.911054]\n",
      "epoch: 68, [Discriminator :: d_loss: 0.006299], [ Generator :: loss: 5.956990]\n",
      "epoch: 69, [Discriminator :: d_loss: 0.055113], [ Generator :: loss: 7.594713]\n",
      "epoch: 70, [Discriminator :: d_loss: 0.727351], [ Generator :: loss: 5.485871]\n",
      "epoch: 71, [Discriminator :: d_loss: 0.549580], [ Generator :: loss: 4.973413]\n",
      "epoch: 72, [Discriminator :: d_loss: 0.248232], [ Generator :: loss: 4.749821]\n",
      "epoch: 73, [Discriminator :: d_loss: 0.302561], [ Generator :: loss: 5.260665]\n",
      "epoch: 74, [Discriminator :: d_loss: 0.079443], [ Generator :: loss: 5.617400]\n",
      "epoch: 75, [Discriminator :: d_loss: 0.044381], [ Generator :: loss: 5.649301]\n",
      "epoch: 76, [Discriminator :: d_loss: 0.030800], [ Generator :: loss: 5.688824]\n",
      "epoch: 77, [Discriminator :: d_loss: 0.026295], [ Generator :: loss: 5.780905]\n",
      "epoch: 78, [Discriminator :: d_loss: 0.023554], [ Generator :: loss: 5.451522]\n",
      "epoch: 79, [Discriminator :: d_loss: 0.017144], [ Generator :: loss: 5.249159]\n",
      "epoch: 80, [Discriminator :: d_loss: 0.035805], [ Generator :: loss: 5.518761]\n",
      "epoch: 81, [Discriminator :: d_loss: 0.031991], [ Generator :: loss: 5.439955]\n",
      "epoch: 82, [Discriminator :: d_loss: 0.029182], [ Generator :: loss: 5.487767]\n",
      "epoch: 83, [Discriminator :: d_loss: 0.095274], [ Generator :: loss: 5.323944]\n",
      "epoch: 84, [Discriminator :: d_loss: 0.062845], [ Generator :: loss: 5.332380]\n",
      "epoch: 85, [Discriminator :: d_loss: 0.075904], [ Generator :: loss: 5.552198]\n",
      "epoch: 86, [Discriminator :: d_loss: 0.134888], [ Generator :: loss: 5.745769]\n",
      "epoch: 87, [Discriminator :: d_loss: 0.018383], [ Generator :: loss: 5.691745]\n",
      "epoch: 88, [Discriminator :: d_loss: 0.050866], [ Generator :: loss: 5.453248]\n",
      "epoch: 89, [Discriminator :: d_loss: 0.041797], [ Generator :: loss: 5.205130]\n",
      "epoch: 90, [Discriminator :: d_loss: 0.057889], [ Generator :: loss: 5.264664]\n",
      "epoch: 91, [Discriminator :: d_loss: 0.044008], [ Generator :: loss: 5.404893]\n",
      "epoch: 92, [Discriminator :: d_loss: 0.088356], [ Generator :: loss: 5.258410]\n",
      "epoch: 93, [Discriminator :: d_loss: 0.106486], [ Generator :: loss: 5.707075]\n",
      "epoch: 94, [Discriminator :: d_loss: 0.012529], [ Generator :: loss: 5.299071]\n",
      "epoch: 95, [Discriminator :: d_loss: 0.040011], [ Generator :: loss: 5.117092]\n",
      "epoch: 96, [Discriminator :: d_loss: 0.037338], [ Generator :: loss: 5.204300]\n",
      "epoch: 97, [Discriminator :: d_loss: 0.112858], [ Generator :: loss: 5.159175]\n",
      "epoch: 98, [Discriminator :: d_loss: 0.102939], [ Generator :: loss: 5.356125]\n",
      "epoch: 99, [Discriminator :: d_loss: 0.051162], [ Generator :: loss: 5.322080]\n",
      "epoch: 100, [Discriminator :: d_loss: 0.022115], [ Generator :: loss: 4.890426]\n",
      "epoch: 101, [Discriminator :: d_loss: 0.080016], [ Generator :: loss: 5.205515]\n",
      "epoch: 102, [Discriminator :: d_loss: 0.048226], [ Generator :: loss: 5.527270]\n",
      "epoch: 103, [Discriminator :: d_loss: 0.081024], [ Generator :: loss: 5.542409]\n",
      "epoch: 104, [Discriminator :: d_loss: 0.039725], [ Generator :: loss: 5.669747]\n",
      "epoch: 105, [Discriminator :: d_loss: 0.017119], [ Generator :: loss: 5.693777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 106, [Discriminator :: d_loss: 0.047691], [ Generator :: loss: 5.443333]\n",
      "epoch: 107, [Discriminator :: d_loss: 0.044183], [ Generator :: loss: 5.268557]\n",
      "epoch: 108, [Discriminator :: d_loss: 0.093047], [ Generator :: loss: 5.286050]\n",
      "epoch: 109, [Discriminator :: d_loss: 0.026212], [ Generator :: loss: 5.301665]\n",
      "epoch: 110, [Discriminator :: d_loss: 0.018043], [ Generator :: loss: 5.178346]\n",
      "epoch: 111, [Discriminator :: d_loss: 0.077666], [ Generator :: loss: 5.211918]\n",
      "epoch: 112, [Discriminator :: d_loss: 0.119742], [ Generator :: loss: 5.370410]\n",
      "epoch: 113, [Discriminator :: d_loss: 0.035637], [ Generator :: loss: 5.154692]\n",
      "epoch: 114, [Discriminator :: d_loss: 0.123328], [ Generator :: loss: 5.188578]\n",
      "epoch: 115, [Discriminator :: d_loss: 0.019465], [ Generator :: loss: 4.850069]\n",
      "epoch: 116, [Discriminator :: d_loss: 0.099290], [ Generator :: loss: 5.686638]\n",
      "epoch: 117, [Discriminator :: d_loss: 0.068323], [ Generator :: loss: 5.106537]\n",
      "epoch: 118, [Discriminator :: d_loss: 0.042809], [ Generator :: loss: 5.353334]\n",
      "epoch: 119, [Discriminator :: d_loss: 0.045175], [ Generator :: loss: 5.460160]\n",
      "epoch: 120, [Discriminator :: d_loss: 0.062509], [ Generator :: loss: 5.487623]\n",
      "epoch: 121, [Discriminator :: d_loss: 0.063673], [ Generator :: loss: 5.454741]\n",
      "epoch: 122, [Discriminator :: d_loss: 0.075231], [ Generator :: loss: 5.714661]\n",
      "epoch: 123, [Discriminator :: d_loss: 0.071185], [ Generator :: loss: 5.646598]\n",
      "epoch: 124, [Discriminator :: d_loss: 0.095196], [ Generator :: loss: 5.494328]\n",
      "epoch: 125, [Discriminator :: d_loss: 0.114738], [ Generator :: loss: 5.278196]\n",
      "epoch: 126, [Discriminator :: d_loss: 0.046515], [ Generator :: loss: 5.978926]\n",
      "epoch: 127, [Discriminator :: d_loss: 0.106285], [ Generator :: loss: 6.358999]\n",
      "epoch: 128, [Discriminator :: d_loss: 0.035839], [ Generator :: loss: 5.931600]\n",
      "epoch: 129, [Discriminator :: d_loss: 0.052577], [ Generator :: loss: 5.313257]\n",
      "epoch: 130, [Discriminator :: d_loss: 0.091119], [ Generator :: loss: 4.761524]\n",
      "epoch: 131, [Discriminator :: d_loss: 0.063862], [ Generator :: loss: 4.902740]\n",
      "epoch: 132, [Discriminator :: d_loss: 0.097009], [ Generator :: loss: 6.868195]\n",
      "epoch: 133, [Discriminator :: d_loss: 0.057832], [ Generator :: loss: 7.068330]\n",
      "epoch: 134, [Discriminator :: d_loss: 0.066699], [ Generator :: loss: 5.402659]\n",
      "epoch: 135, [Discriminator :: d_loss: 0.306287], [ Generator :: loss: 7.734212]\n",
      "epoch: 136, [Discriminator :: d_loss: 0.133040], [ Generator :: loss: 5.767326]\n",
      "epoch: 137, [Discriminator :: d_loss: 0.093801], [ Generator :: loss: 6.191430]\n",
      "epoch: 138, [Discriminator :: d_loss: 0.046135], [ Generator :: loss: 6.573298]\n",
      "epoch: 139, [Discriminator :: d_loss: 0.085188], [ Generator :: loss: 6.444411]\n",
      "epoch: 140, [Discriminator :: d_loss: 0.057636], [ Generator :: loss: 7.401510]\n",
      "epoch: 141, [Discriminator :: d_loss: 0.025083], [ Generator :: loss: 6.730964]\n",
      "epoch: 142, [Discriminator :: d_loss: 0.153105], [ Generator :: loss: 6.993989]\n",
      "epoch: 143, [Discriminator :: d_loss: 0.331837], [ Generator :: loss: 4.433409]\n",
      "epoch: 144, [Discriminator :: d_loss: 1.190109], [ Generator :: loss: 6.266722]\n",
      "epoch: 145, [Discriminator :: d_loss: 0.022037], [ Generator :: loss: 7.279315]\n",
      "epoch: 146, [Discriminator :: d_loss: 0.486202], [ Generator :: loss: 3.516770]\n",
      "epoch: 147, [Discriminator :: d_loss: 0.836125], [ Generator :: loss: 3.545798]\n",
      "epoch: 148, [Discriminator :: d_loss: 0.749049], [ Generator :: loss: 4.073857]\n",
      "epoch: 149, [Discriminator :: d_loss: 0.067228], [ Generator :: loss: 5.247039]\n",
      "epoch: 150, [Discriminator :: d_loss: 0.065010], [ Generator :: loss: 6.415261]\n",
      "epoch: 151, [Discriminator :: d_loss: 0.054281], [ Generator :: loss: 6.252414]\n",
      "epoch: 152, [Discriminator :: d_loss: 0.115937], [ Generator :: loss: 6.663844]\n",
      "epoch: 153, [Discriminator :: d_loss: 0.161177], [ Generator :: loss: 5.289200]\n",
      "epoch: 154, [Discriminator :: d_loss: 0.103858], [ Generator :: loss: 5.395761]\n",
      "epoch: 155, [Discriminator :: d_loss: 0.061020], [ Generator :: loss: 5.659318]\n",
      "epoch: 156, [Discriminator :: d_loss: 0.105041], [ Generator :: loss: 5.743961]\n",
      "epoch: 157, [Discriminator :: d_loss: 0.078093], [ Generator :: loss: 4.466839]\n",
      "epoch: 158, [Discriminator :: d_loss: 0.059413], [ Generator :: loss: 4.689340]\n",
      "epoch: 159, [Discriminator :: d_loss: 0.084495], [ Generator :: loss: 5.215888]\n",
      "epoch: 160, [Discriminator :: d_loss: 0.110007], [ Generator :: loss: 4.085680]\n",
      "epoch: 161, [Discriminator :: d_loss: 0.133415], [ Generator :: loss: 3.295598]\n",
      "epoch: 162, [Discriminator :: d_loss: 0.229232], [ Generator :: loss: 4.588639]\n",
      "epoch: 163, [Discriminator :: d_loss: 0.093877], [ Generator :: loss: 3.922500]\n",
      "epoch: 164, [Discriminator :: d_loss: 0.172551], [ Generator :: loss: 4.456150]\n",
      "epoch: 165, [Discriminator :: d_loss: 0.114268], [ Generator :: loss: 4.448379]\n",
      "epoch: 166, [Discriminator :: d_loss: 0.385446], [ Generator :: loss: 4.513925]\n",
      "epoch: 167, [Discriminator :: d_loss: 0.072912], [ Generator :: loss: 4.213835]\n",
      "epoch: 168, [Discriminator :: d_loss: 0.137053], [ Generator :: loss: 4.439452]\n",
      "epoch: 169, [Discriminator :: d_loss: 0.092291], [ Generator :: loss: 3.511069]\n",
      "epoch: 170, [Discriminator :: d_loss: 0.287194], [ Generator :: loss: 4.302223]\n",
      "epoch: 171, [Discriminator :: d_loss: 0.175851], [ Generator :: loss: 2.594260]\n",
      "epoch: 172, [Discriminator :: d_loss: 0.194827], [ Generator :: loss: 3.448514]\n",
      "epoch: 173, [Discriminator :: d_loss: 0.086731], [ Generator :: loss: 5.147464]\n",
      "epoch: 174, [Discriminator :: d_loss: 0.240599], [ Generator :: loss: 2.779583]\n",
      "epoch: 175, [Discriminator :: d_loss: 0.735516], [ Generator :: loss: 6.729993]\n",
      "epoch: 176, [Discriminator :: d_loss: 0.998293], [ Generator :: loss: 1.976053]\n",
      "epoch: 177, [Discriminator :: d_loss: 1.112367], [ Generator :: loss: 1.280285]\n",
      "epoch: 178, [Discriminator :: d_loss: 0.699512], [ Generator :: loss: 3.528272]\n",
      "epoch: 179, [Discriminator :: d_loss: 0.258252], [ Generator :: loss: 6.650743]\n",
      "epoch: 180, [Discriminator :: d_loss: 0.076952], [ Generator :: loss: 8.387377]\n",
      "epoch: 181, [Discriminator :: d_loss: 0.026651], [ Generator :: loss: 8.657470]\n",
      "epoch: 182, [Discriminator :: d_loss: 0.083524], [ Generator :: loss: 7.946184]\n",
      "epoch: 183, [Discriminator :: d_loss: 0.060813], [ Generator :: loss: 7.135949]\n",
      "epoch: 184, [Discriminator :: d_loss: 0.062934], [ Generator :: loss: 6.678221]\n",
      "epoch: 185, [Discriminator :: d_loss: 0.072976], [ Generator :: loss: 5.777658]\n",
      "epoch: 186, [Discriminator :: d_loss: 0.197746], [ Generator :: loss: 4.937176]\n",
      "epoch: 187, [Discriminator :: d_loss: 0.198070], [ Generator :: loss: 5.177553]\n",
      "epoch: 188, [Discriminator :: d_loss: 0.085768], [ Generator :: loss: 4.564795]\n",
      "epoch: 189, [Discriminator :: d_loss: 0.181635], [ Generator :: loss: 4.816083]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8a315317c43b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-8184a7110a43>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X_train, epochs, batch, save_interval)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mgen_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0msyntetic_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_noise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mx_combined_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlegit_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msyntetic_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\CS\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1165\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mD:\\CS\\Anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\CS\\Anaconda\\lib\\site-packages\\plaidml\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\CS\\Anaconda\\lib\\site-packages\\plaidml\\keras\\backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\CS\\Anaconda\\lib\\site-packages\\plaidml\\__init__.py\u001b[0m in \u001b[0;36mas_ndarray\u001b[1;34m(self, ctx)\u001b[0m\n\u001b[0;32m   1248\u001b[0m                 \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m                 dtype=_NP_TYPES[self.shape.dtype])\n\u001b[1;32m-> 1250\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmmap_current\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m             \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_to_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\CS\\Anaconda\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\CS\\Anaconda\\lib\\site-packages\\plaidml\\__init__.py\u001b[0m in \u001b[0;36mmmap_current\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1231\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmmap_current\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m         mapping = _lib().plaidml_map_buffer_current(self.buffer,\n\u001b[1;32m-> 1233\u001b[1;33m                                                     ctypes.cast(None, _MAP_BUFFER_FUNCTYPE), None)\n\u001b[0m\u001b[0;32m   1234\u001b[0m         yield _View(self.buffer._ctx, mapping, self.shape.dtype, self.shape.ctype,\n\u001b[0;32m   1235\u001b[0m                     _lib().plaidml_get_shape_element_count(self.shape), self.shape, None)\n",
      "\u001b[1;32mD:\\CS\\Anaconda\\lib\\site-packages\\plaidml\\__init__.py\u001b[0m in \u001b[0;36m_check_err\u001b[1;34m(self, result, func, args)\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaidml_compute_grad_wrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_err\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "gan = GAN()\n",
    "gan.train(X_train)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
